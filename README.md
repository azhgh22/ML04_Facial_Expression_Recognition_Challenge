# ML04_Facial_Expression_Recognition_Challenge

training set დავყავი შემდეგნაირად:
      70% - train
      15% - validation
      15% - test

1.   პირველ ექპერიმენტში არანარი პრეპროცესინგი არ ხდება. უბრალოდ ავიღე შემდეგი არქიტექტურა:
  Conv2d -> ReLU -> BatchNorm2d -> Flatten -> Linear -> ReLU -> Linear
  1 ცალი კონვლუციური ლეიერი რომელსაც აქვს 32 channel.
  არაწრფივობისთვის ვიყენებ relu ფუნქციას.
  დანარჩენი სტანდართული ნეირონული ქსელი
  
  training accuracy: 98%
  validation accuracy: 44%
  
  როგორც ვხედავთ ძალიან დიდი ვარიაცია გვაქვს. წავედით overfit-ში.
  ამის მიზეზები შეიძლება იყოს:
  1. საკმარისი დატა არ გვაქვს ( ყველაზე ნაკლებალბათური ). ანუ ვალიდაციის ნაწილში ისეთი სურათები მოხვდა რაც ტრენინგის დროს არ გვქონდა. 
  2. ძალიან კომპლექსური მოდელი გვაქვს და არ აღწერს დატის განაწილებას.

მეორე run-ში ვარიაციის შემცირება ვცადე dropout layer-ების დამატებით. მართალია ვარიაცია ტრანინგ სქორის შემცირებით, თუმცა ვალიდაცია არ გაზრდილა. 
მერე დავამატე (run-3-ში) L2 რეგულარიზაცია(decay_factor=1). როგორც აღმოჩნდა 1 ძალიან დიდი რცხვია მისთვის. და ეგრევე underfit მგვცა.
ტრენინგი 90% ჩამოვარდა 26%, ხოლო ვალიდაციის accuracy-ც 26%. შედეგად მივიღეთ დიდი ბაიასი. აშკარად ზედმეტი რეგულარიზაცია მომივიდა.
