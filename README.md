# ML04_Facial_Expression_Recognition_Challenge

training set დავყავი შემდეგნაირად:
      70% - train
      15% - validation
      15% - test

run1.   პირველ ექპერიმენტში არანარი პრეპროცესინგი არ ხდება. უბრალოდ ავიღე შემდეგი არქიტექტურა:
  Conv2d(1,32, padding=1) -> ReLU -> Flatten -> Linear(48*48*32, 256) -> ReLU -> Linear
  საკმაოდ მარტივი მოდელია. შედეგებიდან გამომდინარე (train-ზე accuracy 47% test-ზე 40%) ჩანს რომ მოდელმა ვერ დაისწავლა საკმარისი ინფორმაცია.
თანაც რადგანაც არ ვიყენებთ bachnorm-ს ჰიპერ პარამეტრების მორგებასა და წონების ინიციალიზაციას დიდი მნიშვნელობა ენიჭება.

run2 ამის შემდეგ დავამატე ორი კონვოლუციური ლეიერი რათა მოდელს შესძელბოდა უფრო მეტის რამის სწავლა, და ასევე თითოეულის შემდეგ ჩავსვი batchnormalization ლეიერი, 
 internal covariance shift -ის პრობლემის მოსაგვარებლად. ეს ლეიერი იმასაც უზრუნველყოფს, რომ თავდაპირველ წონებს ისეთი დიდი გავლენა აღარ ექნებათ outputებზე, რადგან ისინი ყველთვის დანორმალიზდება N(0,1) განაწილებაზე. შედეგად gradient vanishing/exploding პრობლემაც აღარ იქნება. ერთადერთი პრობლემა ისაა, რომ აქტივაციად ვიყენებთ relu-ს,
 BatchNorm ლეიერები კი ჩასმულია LeRu-ს წინ. პრობლემა შეიძლება შეიქმნას თუ რელუს input-ის უმეტესობა უარყოფითი იქნება. თუმცა როგორც შედეგებიდან ჩანს ეს პრობლემა არ შექმნილა,მეტიც ძალიან დიდი ვარიაცია შეგვრჩა ხელთ. 
             train accuracy : 99%
             val accuracy : 47%
      ასევე train-loss -ის გრაფიკს თუ დავაკვირდებით loss ეპოქბის მიხედვით წრფივად მცირდება, რაც დიდი ალბათობით, learning rate-ის დაბალ მნიშვნელობაზე მეტყველებს.
      ცოტას გავზრდი
      ამჯერდა ვარიაციის შემცირებას შევეცდები რეგულარიზაციების დამატებით. (dropout, L2, pooling)

run3. ამჯერად შევეცადე lr-ის ტუნინგს, რათა loss ის შემცირება უფრო სწრაფი ყოფილიყო(წრფივი შემცირება არ გვინდა)
      ასევე დავამატე რეგულარიზაცია dropout-ის სახით p=0.5 ყოველი რელუ ლეიერის შემდეგ. თუმცა როგორც აღმოჩნა ასეთი ჩამატება ზედმეტია და დიდი ბაიასი მოგვცა.
      train accuracy - 30%
      validation accuracy - 30%

run4-5. ამ ჯერად შევეცადე რეგულარიზაციის ტუნინგს, ცვადე არამარტო კარგი dropout-ის შერჩევა, არამედ შემოვიტანე რეგულარიზაცია pooling ლეიერის სახით. ის ყოველ ჯერზე ამცირებს პარამეტრებს, რაც ამცირებს მოდელის კომპლექსურობას შესაბამისად ვარიაციასაც. მიუხედავად იმისა რომ ვარიაცია შემცირადა, validation accuracy 51%-ს ვერ აცდა.
მართალია bias-variance-ის გადმოსახედიდან ასე თუ ისე კარგი მოდელი გვაქვს(5%იანი სხვაობაა ტესტსა და ტრეინს შორის, ნუ ცოტა overffit გვაქვს). მაგრამ 51% accuracy კარგი არ არის. ამის მიზეზი შეიძლება იყოს ის, რომ მოდელი ვერ სწავლობს კარგ feature-ებს. გარდა ამისა ზოგიერთ კლასის მიმართ დატა დაუბალანსებელია. ამიტომ smoothing-ის გამოყენება ასეთ შემთხვევაში კარგი იქნებოდა. მაგრამ მთავარი კითხვაა როგორ დავასწავლოთ უფრო კარგი feature-ები.

run6. ამ გაშვებაზე, ვცდი data Augmentation ტექნიკების დამატებას. ისეთები როგორიცაა, სურათის წაჩოჩება კიდეებისკენ, rotate, random crop... ამით დატაც გამდიდრდება, ეს overfitting-საც შეამცირებს, და მოდელს მისცემს საშუალებას სურათებიდან უფრო კონკრეტულ feature-ებს დააკვირდეს. საინტერესო შედეგი მივიღეთ: დატა აუგმენტაციის დამატებამ 
მოგვცა დიდი ბაიასი 46% ტესტიც და ტრეინიც. ჩემი აზრით ეს ნიშნავს, რომ მოდელმა აუგმენტაციის შედეგად ბევრი კარგი რაღაც ისწავლა, თუმცა რადგან ბევრი რეგულარიზაცია გვქონდა მოდებული მივიღეთ ბიასი. ამიტომ ამჯერად რეგულარიზაცია უნდა შევამციროთ. 
